{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## <span style=\"color:blue\"> Computer Vision - Winter 2024\n",
    "\n",
    "## <span style=\"color:blue\"> Exercise 3 </span>\n",
    "**Reichman University**\n",
    "\n",
    "**Lecturer:** Prof. Yael Moses, RUNI\n",
    "\n",
    "**TA:** Eyal Friedman, RUNI\n",
    "\n",
    "    \n",
    "    \n",
    "**Submission date: 9.2.24** \\\n",
    "Note: In case you need an extension for any reason, you can submit it by 14.2.24. \\\n",
    "No extra extensions will be given.\n",
    "In case you are in miluim - please contact Yael directly.\n",
    "\n",
    "**Your name: [Your Name]**\n",
    "**Your ID: [Your ID]**\n",
    "\n",
    "In this exercise, you will practice projection matrices and epipolar geometry related tasks.\n",
    "\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\"> Submission guidelines:</span>\n",
    "\n",
    "1. Your **zip** file should include the following files only:\n",
    "   - ex3.ipynb\n",
    "   - images you use that were not given \n",
    "2. You should use Jupyter Notebook.\n",
    "3. Name the zip file **'ex3_ID_ID.zip'** and **do not** include any additional directories.\n",
    "4. Submit using *Moodle*.\n",
    "5. Submit on time!\n",
    "6. You can submit this assignment in pairs (no triplets).\n",
    "   * In the case of pair submission, both IDs and names should be added to the notebook.\n",
    "   * One should submit the homework, and the other should submit a simple text file named: ID_ID.txt and nothing else.\n",
    "   *Please make sure that your collaborator submits the HW.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. Write **efficient vectorized** code. \n",
    "2. You are responsible for the correctness of your code and should add as many tests as you see fit. Do not submit your tests unless requested.\n",
    "3. Use `Python 3` and `numpy 1.18.5` or above. Changes to the configuration we provided are at your own risk. Before submitting the exercise, restart the kernel and run the notebook from start to finish to make sure everything works.\n",
    "4. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. Any other imports are forbidden unless provided by us.\n",
    "5. Your code must run without errors. Note, **Code that fails to run will not be graded.**\n",
    "6. Document your code properly.\n",
    "7. Go over Warmup Python - you can find relevant python functions that will make your life easier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# This opens an inteactive figure - use it in part B\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import null_space\n",
    "\n",
    "# This specifies the way plots behave in jupyter notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.cmap'] = 'gray'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Numpy version: \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Section A: Projection\n",
    "\n",
    "In this part you will go over projection matrix,  and use them to project 3D points to an image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Part A1: Projection Matrix \n",
    "Fill the missing values, given partial values of the parameters of the left and right cameras.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right image parameters:**\n",
    "The projection matrix of the right image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "MR = np.array([[1100.504780,          0,   331.023000,   0],\n",
    "               [0,          1097.763735,   259.386377,   0],\n",
    "               [0,                    0,            1,   0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rotation matrix of the right image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "RR = np.array([[1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focal length of the right image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fR = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, replace \"none\" with your answers to the questions. In addition, if there are more than a single possible solution, choose one.\n",
    "Compute the right image center (principal point):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OxR = None\n",
    "OyR = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the right image scale factor which is consistent with MR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SxR = None\n",
    "SyR = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the right image intrinsic matrix which is consistent with MR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MintR = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Left image parameters**\n",
    " \n",
    "Left image center (principal point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OxL = 320.798101 \n",
    "OyL = 236.431326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SxL = 1095.671499\n",
    "SyL = 1094.559584 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal length of the left image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation vector w.r.t. the world origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL = -np.array([[178.2218,18.8171,-13.7744]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation matrix of the left image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL = np.array([[ 0.9891,    0.0602,   -0.1346],\n",
    "               [-0.0590,    0.9982,    0.0134],\n",
    "               [0.1351,   -0.0053,    0.9908]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the intrinsic projection matrix of the left camera: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MintL = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the projection matrix of the left camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the COP of the left and the right images, in Cartesian coordinates:   \n",
    "\n",
    "(You may use the the function *null_space* from *scipy.linalg*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL = None\n",
    "CR = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the distance between CL and CR:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Part A2: Hands on Triangulation\n",
    "\n",
    "Write a function p = proj(M,P) that recieves as input the 3D point P in Euclidean coordinates and a projection matrix M, and outputs the 2D  Euclidean coordinates of the projected point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for proj function\n",
    "def proj(M,P):\n",
    "    \n",
    "    # your code\n",
    "    pass\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Answer Quesion:**\\\n",
    "Given object points in the world coordinate system,  P=(-140,50,1200) and Q=(30,100,2000).\n",
    "\n",
    "a.\tWhat are the coordinates (Euclidean) of the points in the left camera coordinate system?\\\n",
    "b.\tWhat are the coordinates (Euclidean) of the points in the right camera coordinate system?\n",
    "    \n",
    "Note: the camera coordinate system rather than the image coordinate system (PL means the 3D coordinates in the left **camera** cordinates system, and pL means the 2D coordinates in the left **image** coordinates system.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Your answer:**\\\n",
    "   ...\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PL = None\n",
    "PR = None\n",
    "QL = None\n",
    "QR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[-140],[50],[1200]])\n",
    "pL = proj(ML,P)\n",
    "pR = proj(MR,P)\n",
    "\n",
    "Q = np.array([[30],[100],[2000]]) \n",
    "qL = proj(ML,Q)\n",
    "qR = proj(MR,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read two images and display the projections of P and Q on the two given images ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imL = cv2.imread('left.tif', cv2.IMREAD_GRAYSCALE)\n",
    "imR = cv2.imread('right.tif', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = (14.0, 14.0) \n",
    "f, ((ax1, ax2)) = plt.subplots(1, 2, sharex='col', sharey='row')\n",
    "\n",
    "ax1.imshow(imL, cmap='gray'), ax1.set_title('Left image'), ax1.scatter(pL[0], pL[1], color='r'), \\\n",
    "    ax1.scatter(qL[0],qL[1], color = 'b')\n",
    "ax2.imshow(imR, cmap='gray'), ax2.set_title('Right image'), ax2.scatter(pR[0], pR[1], color = 'r'), \\\n",
    "    ax2.scatter(qR[0],qR[1], color = 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\"> Answer Question:**\\\n",
    "Look at the projection of each of the points in the two images. One pair looks as expected, and the other does not. Please give a short explanation of what may have caused it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Your answer:**\\\n",
    "   ...\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Part B: Epipolar Geometry\n",
    "Compute the fundamental matrix F and the epipoles eL and eR of the left and right images, using their projection matrices.\\\n",
    "Note, you should normalize F by F(3,3) for improved precision.\n",
    "\n",
    "For the epipoles' computation use the MR and ML and the Center of projections.\n",
    "\n",
    "**<span style=\"color:blue\">Answer Question:**\n",
    "Can you double check if they are correct using F? If so, check it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Your answer:**\\\n",
    "   ...\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eL = None\n",
    "eR = None\n",
    "F = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epipolar lines ##\n",
    "\n",
    "Click on three different points of the **right** image, and check if the epipolar lines on the left image pass through a pixel that corresponds to the one you picked in the right image. Output the set of epipolar lines overlayed on the pair of  images as shown below.\n",
    "\n",
    "To do so you can use:\n",
    "1. The code below opens the images in a seperate window. You can click on the right image and  capture the click's coordinates by using the function *plt.ginput*.\n",
    "2. Take each point (this can be done by a loop) and calculate its epipolar line  on the left image using F.\n",
    "3. Compute the two endpoints of the line in the image to plot it on the left image. \\\n",
    "    **Hint**: you have linear coefficients - (a,b,c). Calculate the y value in the image for x=0, and x=image.width and plot the result.\\\n",
    "    Use: ax2.plot((x0. xWidth),(yx0, yxWidth))\n",
    "4. Use the set of the points of the right image that you collected, and draw the epipolar lines on the right image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This sould open a new figure window outside of jupyter notebook\n",
    "%matplotlib qt  \n",
    "\n",
    "imL = cv2.imread('Left.tif', cv2.IMREAD_GRAYSCALE)\n",
    "imR = cv2.imread('Right.tif', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = (14.0, 14.0) \n",
    "f, ((ax1, ax2)) = plt.subplots(1, 2, sharex='col', sharey='row')\n",
    "\n",
    "ax1.imshow(imL, cmap='gray'), ax1.set_title('Left image')\n",
    "ax2.imshow(imR, cmap='gray'), ax2.set_title('Right image')\n",
    "\n",
    "data = plt.ginput(3)\n",
    "\n",
    "x_val = [x[0] for x in data]\n",
    "y_val = [x[1] for x in data]\n",
    "\n",
    "ax2.scatter(x_val, y_val, color='r')\n",
    "\n",
    "for x in data: \n",
    "    # Write your own implementation here.\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what you should see:\n",
    "![Epipolar](epipolarLines1.png \"Epipolar Lines example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:blue\">Part C : SIFT and RANSAC/LMedS\n",
    "**Follow the matching to compute F.**\n",
    "\n",
    "https://docs.opencv.org/master/da/de9/tutorial_py_epipolar_geometry.html \n",
    "\n",
    "The example attached here needs some twicks to make it work. First you need to uninstall the opencv package and to install to opencv-contrib package:\n",
    "- pip uninstall opencv-python \n",
    "\n",
    "Then install the contrib version with this:\n",
    "- pip install opencv-contrib-python\n",
    "\n",
    "**<span style=\"color:red\"> Now, you have to use those lines:**\n",
    "- **sift = cv2.xfeatures2d.SIFT_create()**\n",
    "- **kp1, des1 = sift.detectAndCompute(img1, None)**\n",
    "\n",
    "\n",
    "Hereby, we will find the corresponding featues using the SIFT algorithm and match the closet points. The plotted figure showes the best 300 matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imL = cv2.imread('Left.tif', cv2.IMREAD_GRAYSCALE)\n",
    "imR = cv2.imread('Right.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initiate SIFT detector\n",
    "# In the link above you need to change the next line from cv.SIFT to cv2.xfeatures2d.\n",
    "# Instead of: sift = cv2.SIFT() use:\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(imL,None)\n",
    "kp2, des2 = sift.detectAndCompute(imR,None)\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "# create FlannBasedMatcher object\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "# Match descriptors.\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "matching = []\n",
    "# Building a list of points screened by ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.8*n.distance:\n",
    "        pts2.append(kp2[m.trainIdx].pt)\n",
    "        pts1.append(kp1[m.queryIdx].pt)\n",
    "        matching.append(m)\n",
    "        \n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matching = sorted(matching, key = lambda x:x.distance)\n",
    "        \n",
    "# Draw first 300 matches.\n",
    "img3 = np.array([])\n",
    "img3 = cv2.drawMatches(imL, kp1, imR, kp2, matching[:300], outImg = img3, flags =2)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14.0, 14.0) \n",
    "f, ((ax1)) = plt.subplots(1, 1, sharex='col', sharey='row')\n",
    "ax1.imshow(img3, cmap='gray'), ax1.set_title('Matches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> Not for submission:\n",
    "\n",
    "    Look at the obtain results.\n",
    "\n",
    "    a. Do you think all matches are correct?\n",
    "    b. In which regions of the scene, most of the reliable matches were found?\n",
    "    c. Try the worst 200 mathces as well -- matching[-1-200:]\n",
    "\n",
    "Now, we will use the found matches to compute **F** using *cv2.findFundamentalMat()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "\n",
    "# Computing the F matrix\n",
    "F_calc, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel()==1]\n",
    "pts2 = pts2[mask.ravel()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float' : '{:0.7f}'.format})\n",
    "print(F_calc.T)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now lets check the computed F_calc:\n",
    "1. Use it to draw the epipolar line as in the example above (change F to F_calc.T)\n",
    "2. Compute the distance between the computed epipoles by F and by F_calc in each of the images.\n",
    "\n",
    "Hint: You can use scipy.linalg import null_space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\">Answer Question:**\\\n",
    "    Do you see any differences?\n",
    "    \n",
    "**<span style=\"color:blue\">Your answer:**\\\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Your part in this section :) ###\n",
    "\n",
    "#### Take two images by your camera and compute the epipolar geometry using LMedS ####\n",
    "\n",
    "Please submit: 5 corresponding epipolar lines overlayed on   your pair of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:blue\"> Part D: Answer the following question\n",
    "    \n",
    "Consider two rectified images that are related by translation along the $y$-axis.\n",
    "\n",
    "1. What is the epipolar line on the bottom image for the point $(x, y)$ on the top image?\n",
    "2. What is the Fundamental matrix of the pair of images? Explain your answer and prove that it is consistent with your answer to (1).\n",
    "3. Where is the epipole of the top image? Prove your answer formally using your answer to (2).\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:blue\"> Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
